{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLKKgxGq+X3QvFXfLl7DdN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raki-rankawat/stm32/blob/main/CIFAR10_Pruned_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Trained CIFAR10 Model"
      ],
      "metadata": {
        "id": "2Gy6-lXy-xnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuJDbGbq-XYC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIw9mUHD-kHR",
        "outputId": "78601e1a-499e-47fe-9a4e-cba81aa8df07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 64\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "VPT_nmEm-81Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "class CIFARConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 32 -> 16\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 16 -> 8\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 8 -> 4\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 4 -> 2\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.training:\n",
        "          x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "kkZXMWXG---V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CIFARConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_model.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC8xWOea_MIe",
        "outputId": "0c62442d-3f4f-4830-f57b-7f9a5d62541c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Before Pruning\n",
        "def test_accuracy_full(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(x)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "acc_base = test_accuracy_full(model, test_loader)\n",
        "print(f\"✅ PyTorch FULL test accuracy (BASE): {acc_base:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ODt70AL_OnG",
        "outputId": "8a323475-cdb9-4747-8755-0ee3c26d2a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch FULL test accuracy (BASE): 78.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruning"
      ],
      "metadata": {
        "id": "MLycw9cHBELY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRUNE_AMOUNT = 0.20          # 10% | 20% | 30%\n",
        "PRUNE_TYPE = \"structured\"    # \"structured\" | \"unstructured\""
      ],
      "metadata": {
        "id": "_EAzMVUkJJfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_to_prune = [\n",
        "    (model.conv2, \"weight\"),\n",
        "    (model.conv3, \"weight\"),\n",
        "    (model.conv4, \"weight\"),\n",
        "]"
      ],
      "metadata": {
        "id": "MSTGcU0CJLmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply pruning\n",
        "if PRUNE_TYPE == \"structured\":\n",
        "    for layer, param in layers_to_prune:\n",
        "        prune.ln_structured(layer, name=param, amount=PRUNE_AMOUNT, n=2, dim=0)\n",
        "    print(f\"✅ Structured pruning: {PRUNE_AMOUNT*100:.0f}% filters on conv2/conv3/conv4\")\n",
        "else:\n",
        "    for layer, param in layers_to_prune:\n",
        "        prune.l1_unstructured(layer, name=param, amount=PRUNE_AMOUNT)\n",
        "    print(f\"✅ Unstructured pruning: {PRUNE_AMOUNT*100:.0f}% weights on conv2/conv3/conv4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKfZD6DaVb86",
        "outputId": "a94c6951-39ef-42b9-a02c-de2987ce3d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Structured pruning: 20% filters on conv2/conv3/conv4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy After Pruning\n",
        "acc_after_prune = test_accuracy_full(model, test_loader)\n",
        "print(f\"✅ PyTorch FULL test accuracy (AFTER PRUNE, before FT): {acc_after_prune:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62FgfgWmV1Fd",
        "outputId": "ad95e5a5-ae05-4855-cbf2-8926fcd87afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch FULL test accuracy (AFTER PRUNE, before FT): 59.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tune"
      ],
      "metadata": {
        "id": "S26_qsxQWKrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FT_EPOCHS = 3\n",
        "FT_LR = 1e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=FT_LR)"
      ],
      "metadata": {
        "id": "xEddn_TmWMnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, FT_EPOCHS + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    print(f\"FT Epoch {epoch}/{FT_EPOCHS} | Train Loss: {running_loss/total:.4f} | Train Acc: {100*correct/total:.2f}%\")\n",
        "\n",
        "print(f\"Fine-tune time: {(time.time() - start_time)/60:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2022n7OzWRDn",
        "outputId": "f16df3cf-70ff-4a89-af33-df84ead2958a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FT Epoch 1/3 | Train Loss: 0.7382 | Train Acc: 74.29%\n",
            "FT Epoch 2/3 | Train Loss: 0.6765 | Train Acc: 76.70%\n",
            "FT Epoch 3/3 | Train Loss: 0.6621 | Train Acc: 77.15%\n",
            "Fine-tune time: 3.62 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy After Fine-Tune\n",
        "acc_after_ft = test_accuracy_full(model, test_loader)\n",
        "print(f\"✅ PyTorch FULL test accuracy (AFTER FT): {acc_after_ft:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSaGaeB2WtpZ",
        "outputId": "7125b8a0-3434-4d55-8ff8-3be1aa483652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch FULL test accuracy (AFTER FT): 79.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make pruning permanent before saving/exporting\n",
        "for layer, param in layers_to_prune:\n",
        "    prune.remove(layer, param)\n",
        "\n",
        "PRUNED_FT_PTH = \"/content/drive/My Drive/Colab Notebooks/stm_cifar10_model_pruned.pth\"\n",
        "torch.save(model.state_dict(), PRUNED_FT_PTH)\n",
        "print(\"✅ Saved pruned+finetuned weights:\", PRUNED_FT_PTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQIFs_OSWfaD",
        "outputId": "dc083204-c5a9-491d-fb5b-f6e564e1b856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved pruned+finetuned weights: /content/drive/My Drive/Colab Notebooks/stm_cifar10_model_pruned.pth\n"
          ]
        }
      ]
    }
  ]
}