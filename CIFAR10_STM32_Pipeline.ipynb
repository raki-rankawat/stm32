{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtHMh5Pkc9k7NW7ztF+KAb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/CIFAR10_STM32_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Trained CIFAR10 Model"
      ],
      "metadata": {
        "id": "iCzxqh8UwD5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "YuV-mXqiv-1B"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "oj6VOdpGrjUS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hHxFA7fv330",
        "outputId": "a0b4c857-c33e-43fe-eca7-e0bba0e70312"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 1\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "7QqoNOESx2U9"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "class CIFARConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 32 -> 16\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 16 -> 8\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 8 -> 4\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 4 -> 2\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.training:\n",
        "          x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "wYSAi6yHwb_m"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "model = CIFARConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_model.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-wLnypNwmBC",
        "outputId": "e2bd6682-874b-4e96-9c71-57a14b86fc8a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on the 200 samples\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= 200:\n",
        "            break\n",
        "        out = model(x)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"PyTorch accuracy on first 200:\", 100*correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TszNYjf-Rr9l",
        "outputId": "f3f567a8-430b-42ff-ad8c-6d10ec83bbae"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch accuracy on first 200: 69.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FP32 Pipeline"
      ],
      "metadata": {
        "id": "-JUzB_gez1LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export To ONNX\n",
        "def export_onnx(model, onnx_path):\n",
        "    model.eval()\n",
        "    dummy = torch.randn(1, 3, 32, 32)  # NCHW\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        export_params=True,\n",
        "        opset_version=18,\n",
        "        do_constant_folding=True,\n",
        "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"logits\": {0: \"batch_size\"}},\n",
        "        dynamo=False\n",
        "    )\n",
        "    onnx.checker.check_model(onnx_path, full_check=False)\n",
        "    print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "export_onnx(model, \"cifar10_convnet_fp32.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSoWifXwXx8",
        "outputId": "707bb602-8571-44af-eb42-76843d600e95"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model saved to: cifar10_convnet_fp32.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1261316891.py:6: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect N samples (SAVE NCHW for ST to avoid any internal NHWC->NCHW conversion)\n",
        "model.eval()\n",
        "\n",
        "N = 200\n",
        "inputs_nchw = []\n",
        "logits = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= N:\n",
        "            break\n",
        "\n",
        "        out = model(x)\n",
        "\n",
        "        # Keep NCHW (1,3,32,32) -> store (3,32,32)\n",
        "        x_nchw = x.detach().cpu().numpy().astype(np.float32)   # (1,3,32,32)\n",
        "        out_np = out.detach().cpu().numpy()[0].astype(np.float32)  # (10,)\n",
        "\n",
        "        inputs_nchw.append(x_nchw[0])   # (3,32,32)\n",
        "        logits.append(out_np)           # (10,)\n",
        "        labels.append(int(y.item()))\n",
        "\n",
        "inputs_nchw = np.stack(inputs_nchw, axis=0)       # (N,3,32,32)\n",
        "logits = np.stack(logits, axis=0)                 # (N,10)\n",
        "labels = np.array(labels, dtype=np.int32)         # (N,)\n",
        "\n",
        "np.savez(\"cifar10_val_200_io.npz\", input=inputs_nchw, logits=logits)\n",
        "np.savez(\"cifar10_labels_200.npz\", label=labels)\n",
        "\n",
        "print(\"Saved input shape:\", inputs_nchw.shape, \"min/max:\", inputs_nchw.min(), inputs_nchw.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZQUyx-x3mw8",
        "outputId": "04ab7613-8d32-45d1-9f08-f795f3436764"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved input shape: (200, 3, 32, 32) min/max: -1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Accuracy\n",
        "def compute_accuracy(\n",
        "    labels_npz_path,\n",
        "    outputs_npz_path,\n",
        "    output_key=\"c_outputs_1\",\n",
        "    num_classes=10,\n",
        "    as_percentage=False\n",
        "):\n",
        "    labels = np.load(labels_npz_path)[\"label\"].astype(np.int64)\n",
        "    out = np.load(outputs_npz_path)\n",
        "\n",
        "    logits = out[output_key].reshape(len(labels), num_classes)\n",
        "    pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    return acc * 100 if as_percentage else acc"
      ],
      "metadata": {
        "id": "wZGXuf1w48Ox"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_accuracy(\n",
        "    \"cifar10_labels_200.npz\",\n",
        "    \"network_val_io.npz\",\n",
        "    as_percentage=True\n",
        ")\n",
        "\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgd4etn54_TG",
        "outputId": "42df1745-3a2a-4c37-9401-4fce64648293"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 69.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Int8 Pipeline"
      ],
      "metadata": {
        "id": "qt5jMm4l5I9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibration NPZ (inputs only)\n",
        "def make_calib_npz(test_dataset, N=200, out_path=\"cifar10_calib_200.npz\"):\n",
        "    loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= N:\n",
        "                break\n",
        "            xs.append(x.detach().cpu().numpy()[0].astype(np.float32))\n",
        "\n",
        "    xs = np.stack(xs, axis=0)\n",
        "    np.savez(out_path, input=xs)\n",
        "    print(\"Saved calib:\", out_path, xs.shape)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "PubKnoOq5J1e"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantize FP32 ONNX â†’ INT8 ONNX (QDQ)\n",
        "class CalibReader(CalibrationDataReader):\n",
        "    def __init__(self, npz_path, input_name=\"input\"):\n",
        "        self.x = np.load(npz_path)[\"input\"].astype(np.float32)\n",
        "        self.input_name = input_name\n",
        "        self.i = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.i >= len(self.x):\n",
        "            return None\n",
        "        batch = self.x[self.i:self.i+1]\n",
        "        self.i += 1\n",
        "        return {self.input_name: batch}\n",
        "\n",
        "def quantize_int8_qdq(fp32_onnx=\"cifar10_convnet_fp32.onnx\",\n",
        "                      calib_npz=\"cifar10_calib_200.npz\",\n",
        "                      int8_onnx=\"cifar10_lenet_int8_static_qdq.onnx\"):\n",
        "    reader = CalibReader(calib_npz, input_name=\"input\")\n",
        "\n",
        "    quantize_static(\n",
        "        model_input=fp32_onnx,\n",
        "        model_output=int8_onnx,\n",
        "        calibration_data_reader=reader,\n",
        "        quant_format=QuantFormat.QDQ,\n",
        "        activation_type=QuantType.QInt8,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        per_channel=True,\n",
        "    )\n",
        "    print(\"Saved INT8:\", int8_onnx)\n",
        "    return int8_onnx"
      ],
      "metadata": {
        "id": "zg-L8oJQ5NrQ"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calib_npz = make_calib_npz(test_dataset, N=200, out_path=\"cifar10_calib_200.npz\")\n",
        "quantize_int8_qdq(\"cifar10_convnet_fp32.onnx\", calib_npz, \"cifar10_convnet_int8_static_qdq.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "uXg5DiPL5Plz",
        "outputId": "ef1bdc99-6512-4d02-f040-88e185cbdb42"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved calib: cifar10_calib_200.npz (200, 3, 32, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved INT8: cifar10_convnet_int8_static_qdq.onnx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cifar10_convnet_int8_static_qdq.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = np.load(\"network_val_io.npz\")\n",
        "print(\"keys:\", d.files)\n",
        "for k in d.files:\n",
        "    print(k, d[k].shape, d[k].dtype)\n",
        "\n",
        "acc = compute_accuracy(\n",
        "    \"cifar10_labels_200.npz\",\n",
        "    \"network_val_io.npz\",\n",
        "    as_percentage=True\n",
        ")\n",
        "\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCcBruoW5RaS",
        "outputId": "e01396ea-b46c-4d55-be54-635b521536f5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys: ['m_inputs_1', 'm_outputs_1', 'c_inputs_1', 'c_outputs_1']\n",
            "m_inputs_1 (200, 3, 32, 32) float32\n",
            "m_outputs_1 (200, 10) float64\n",
            "c_inputs_1 (200, 3, 32, 32) int8\n",
            "c_outputs_1 (200, 1, 1, 10) int8\n",
            "STM32 accuracy: 68.5\n"
          ]
        }
      ]
    }
  ]
}