{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLNpUf9eDtRHh4Tyrw64aW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raki-rankawat/stm32/blob/main/CIFAR10_STM32_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Trained CIFAR10 Model\n"
      ],
      "metadata": {
        "id": "iCzxqh8UwD5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "YuV-mXqiv-1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6202452-0c47-4db8-f0a4-f56777133833"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oj6VOdpGrjUS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hHxFA7fv330",
        "outputId": "8694dd85-b69b-409a-c997-de2d19d46297"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 1\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "7QqoNOESx2U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529129f3-4437-4e60-88aa-28e573cd30a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 61.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model for CIFAR10 & CIFAR10 Pruned\n",
        "class CIFARConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 32 -> 16\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 16 -> 8\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 8 -> 4\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 4 -> 2\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.training:\n",
        "          x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "wYSAi6yHwb_m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model for CIFAR10 KD\n",
        "class StudentNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
        "    self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.max_pool2d(x, 2) # 32 -> 16\n",
        "\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.max_pool2d(x, 2) # 16 -> 8\n",
        "\n",
        "    x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "mwjyV-Xms4f-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights for CIFAR10 & CIFAR10 Pruned\n",
        "model = CIFARConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_model.pth\", map_location=torch.device('cpu')))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_pruned_model.pth\", map_location=torch.device('cpu'))) # Pruned Model"
      ],
      "metadata": {
        "id": "2-wLnypNwmBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df45cb0-3205-4e5f-a23b-43a0e98682f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load weights for CIFAR10 KD\n",
        "# model = StudentNet()\n",
        "# model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_kd_model.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "V-gVUA6gtI9K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on the 200 samples\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= 200:\n",
        "            break\n",
        "        out = model(x)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"PyTorch accuracy on first 200:\", 100*correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TszNYjf-Rr9l",
        "outputId": "d523cc43-6b21-4e8b-fe5b-ee3595572df5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch accuracy on first 200: 81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FP32 Pipeline"
      ],
      "metadata": {
        "id": "-JUzB_gez1LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export To ONNX\n",
        "def export_onnx(model, onnx_path):\n",
        "    model.eval()\n",
        "    dummy = torch.randn(1, 3, 32, 32)  # NCHW\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        export_params=True,\n",
        "        opset_version=18,\n",
        "        do_constant_folding=True,\n",
        "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"logits\": {0: \"batch_size\"}},\n",
        "        dynamo=False\n",
        "    )\n",
        "    onnx.checker.check_model(onnx_path, full_check=False)\n",
        "    print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "export_onnx(model, \"cifar10_convnet_fp32.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSoWifXwXx8",
        "outputId": "2a8483f7-7a3c-4897-b372-f284993067f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1261316891.py:6: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model saved to: cifar10_convnet_fp32.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect N samples (SAVE NCHW for ST to avoid any internal NHWC->NCHW conversion)\n",
        "model.eval()\n",
        "\n",
        "N = 200\n",
        "inputs_nchw = []\n",
        "logits = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= N:\n",
        "            break\n",
        "\n",
        "        out = model(x)\n",
        "\n",
        "        # Keep NCHW (1,3,32,32) -> store (3,32,32)\n",
        "        x_nchw = x.detach().cpu().numpy().astype(np.float32)   # (1,3,32,32)\n",
        "        out_np = out.detach().cpu().numpy()[0].astype(np.float32)  # (10,)\n",
        "\n",
        "        inputs_nchw.append(x_nchw[0])   # (3,32,32)\n",
        "        logits.append(out_np)           # (10,)\n",
        "        labels.append(int(y.item()))\n",
        "\n",
        "inputs_nchw = np.stack(inputs_nchw, axis=0)       # (N,3,32,32)\n",
        "logits = np.stack(logits, axis=0)                 # (N,10)\n",
        "labels = np.array(labels, dtype=np.int32)         # (N,)\n",
        "\n",
        "np.savez(\"cifar10_val_200_io.npz\", input=inputs_nchw, logits=logits)\n",
        "np.savez(\"cifar10_labels_200.npz\", label=labels)\n",
        "\n",
        "print(\"Saved input shape:\", inputs_nchw.shape, \"min/max:\", inputs_nchw.min(), inputs_nchw.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZQUyx-x3mw8",
        "outputId": "278d69c1-2190-4b96-dea3-af6095a32e66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved input shape: (200, 3, 32, 32) min/max: -1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Accuracy\n",
        "def compute_accuracy(\n",
        "    labels_npz_path,\n",
        "    outputs_npz_path,\n",
        "    output_key=\"c_outputs_1\",\n",
        "    num_classes=10,\n",
        "    as_percentage=False\n",
        "):\n",
        "    labels = np.load(labels_npz_path)[\"label\"].astype(np.int64)\n",
        "    out = np.load(outputs_npz_path)\n",
        "\n",
        "    logits = out[output_key].reshape(len(labels), num_classes)\n",
        "    pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    return acc * 100 if as_percentage else acc"
      ],
      "metadata": {
        "id": "wZGXuf1w48Ox"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_accuracy(\n",
        "    \"cifar10_labels_200.npz\",\n",
        "    \"network_val_io.npz\",\n",
        "    as_percentage=True\n",
        ")\n",
        "\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgd4etn54_TG",
        "outputId": "dbce566a-6f09-45b9-ce62-7d8ccf3643a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Int8 Pipeline"
      ],
      "metadata": {
        "id": "qt5jMm4l5I9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibration NPZ (inputs only)\n",
        "def make_calib_npz(test_dataset, N=200, out_path=\"cifar10_calib_200.npz\"):\n",
        "    loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= N:\n",
        "                break\n",
        "            xs.append(x.detach().cpu().numpy()[0].astype(np.float32))\n",
        "\n",
        "    xs = np.stack(xs, axis=0)\n",
        "    np.savez(out_path, input=xs)\n",
        "    print(\"Saved calib:\", out_path, xs.shape)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "PubKnoOq5J1e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantize FP32 ONNX → INT8 ONNX (QDQ)\n",
        "class CalibReader(CalibrationDataReader):\n",
        "    def __init__(self, npz_path, input_name=\"input\"):\n",
        "        self.x = np.load(npz_path)[\"input\"].astype(np.float32)\n",
        "        self.input_name = input_name\n",
        "        self.i = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.i >= len(self.x):\n",
        "            return None\n",
        "        batch = self.x[self.i:self.i+1]\n",
        "        self.i += 1\n",
        "        return {self.input_name: batch}\n",
        "\n",
        "def quantize_int8_qdq(fp32_onnx=\"cifar10_convnet_fp32.onnx\",\n",
        "                      calib_npz=\"cifar10_calib_200.npz\",\n",
        "                      int8_onnx=\"cifar10_lenet_int8_static_qdq.onnx\"):\n",
        "    reader = CalibReader(calib_npz, input_name=\"input\")\n",
        "\n",
        "    quantize_static(\n",
        "        model_input=fp32_onnx,\n",
        "        model_output=int8_onnx,\n",
        "        calibration_data_reader=reader,\n",
        "        quant_format=QuantFormat.QDQ,\n",
        "        activation_type=QuantType.QInt8,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        per_channel=True,\n",
        "    )\n",
        "    print(\"Saved INT8:\", int8_onnx)\n",
        "    return int8_onnx"
      ],
      "metadata": {
        "id": "zg-L8oJQ5NrQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calib_npz = make_calib_npz(test_dataset, N=200, out_path=\"cifar10_calib_200.npz\")\n",
        "quantize_int8_qdq(\"cifar10_convnet_fp32.onnx\", calib_npz, \"cifar10_convnet_int8_static_qdq.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "uXg5DiPL5Plz",
        "outputId": "45bfb6ce-eb09-4a8d-88f9-6217e79d4168"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved calib: cifar10_calib_200.npz (200, 3, 32, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved INT8: cifar10_convnet_int8_static_qdq.onnx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cifar10_convnet_int8_static_qdq.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d = np.load(\"network_val_io.npz\")\n",
        "# print(\"keys:\", d.files)\n",
        "# for k in d.files:\n",
        "#     print(k, d[k].shape, d[k].dtype)\n",
        "\n",
        "acc = compute_accuracy(\n",
        "    \"cifar10_labels_200.npz\",\n",
        "    \"network_val_io.npz\",\n",
        "    as_percentage=True\n",
        ")\n",
        "\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "id": "eCcBruoW5RaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e08738-989a-4538-e1d5-8f57b0d7e0e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 81.0\n"
          ]
        }
      ]
    }
  ]
}