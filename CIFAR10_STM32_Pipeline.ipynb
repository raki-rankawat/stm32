{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAVemZwTzhhsJ7Fztxl/fL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/CIFAR10_STM32_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch To ONNX"
      ],
      "metadata": {
        "id": "iCzxqh8UwD5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "YuV-mXqiv-1B"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "oj6VOdpGrjUS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hHxFA7fv330",
        "outputId": "c9affd1a-9d39-4257-8859-83b626bbb24f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 1\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "7QqoNOESx2U9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "class CIFARConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 32 -> 16\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 16 -> 8\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 8 -> 4\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 4 -> 2\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "wYSAi6yHwb_m"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "model = CIFARConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_cifar10_model.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-wLnypNwmBC",
        "outputId": "cb45fb37-49f2-4283-c57d-54c42424dd49"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export To ONNX\n",
        "def export_onnx(model, onnx_path):\n",
        "  model.eval()\n",
        "\n",
        "  dummy = torch.randn(1, 3, 32, 32)  # 3 channels and 32x32 for CIFAR-10\n",
        "\n",
        "  torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        opset_version=18,\n",
        "        do_constant_folding=True,\n",
        "        training=torch.onnx.TrainingMode.EVAL,\n",
        "        dynamic_axes={'input': {0: 'batch'}, 'logits': {0: 'batch'}},\n",
        "    )\n",
        "\n",
        "export_onnx(model, \"cifar10_fp32.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSoWifXwXx8",
        "outputId": "656f59c6-e340-4cc5-d2ea-9f7707759b60"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-282632450.py:7: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `CIFARConvNet([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `CIFARConvNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 5 of general pattern rewrite rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FP32 Pipeline"
      ],
      "metadata": {
        "id": "-JUzB_gez1LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect N samples\n",
        "N = 200\n",
        "inputs_nhwc = []\n",
        "logits = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (x, y) in enumerate(test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    if i >= N:\n",
        "      break\n",
        "\n",
        "    out = model(x)\n",
        "    # convert input to NHWC (1x28x28x1)\n",
        "    x_nhwc = x.numpy().transpose(0, 2, 3, 1).astype(np.float32)\n",
        "    inputs_nhwc.append(x_nhwc[0])\n",
        "    logits.append(out.numpy()[0].astype(np.float32))\n",
        "    labels.append(int(y.item()))\n",
        "\n",
        "inputs_nhwc = np.stack(inputs_nhwc, axis=0)\n",
        "logits = np.stack(logits, axis=0)\n",
        "labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "# Save files\n",
        "np.savez(\"cifar10_calib_200.npz\", input=inputs_nhwc) # For quantization later\n",
        "np.savez(\"cifar10_val_200_io.npz\", input=inputs_nhwc, logits=logits)\n",
        "np.savez(\"cifar10_labels_200.npz\", label=labels)"
      ],
      "metadata": {
        "id": "HaSac7d7yp6j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on the same first 200 samples (same as exported)\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= 200:\n",
        "            break\n",
        "        out = model(x)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"PyTorch accuracy on first 200:\", 100*correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TszNYjf-Rr9l",
        "outputId": "4f8b4cce-0db2-47c1-e1d7-712073c2b5cd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch accuracy on first 200: 68.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on STM32\n",
        "def compute_accuracy(\n",
        "    labels_npz_path,\n",
        "    outputs_npz_path,\n",
        "    output_key=\"c_outputs_1\",\n",
        "    num_classes=10,\n",
        "    as_percentage=False\n",
        "):\n",
        "    labels = np.load(labels_npz_path)[\"label\"].astype(np.int64)\n",
        "    out = np.load(outputs_npz_path)\n",
        "\n",
        "    logits = out[output_key].reshape(len(labels), num_classes)\n",
        "    pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    return acc * 100 if as_percentage else acc"
      ],
      "metadata": {
        "id": "2_wwpF1VFeGP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_accuracy(\n",
        "    \"cifar10_labels_200.npz\",\n",
        "    \"network_val_io.npz\",\n",
        "    as_percentage=True\n",
        ")\n",
        "\n",
        "print(\"STM32 FP32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmB0s_ECFjvE",
        "outputId": "261bf6ee-bae0-4339-b792-3333b76f84d2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 FP32 accuracy: 14.000000000000002\n"
          ]
        }
      ]
    }
  ]
}