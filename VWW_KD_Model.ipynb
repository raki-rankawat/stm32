{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/ORSlU3qPqJ8PwenhCHsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raki-rankawat/stm32/blob/main/VWW_KD_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Fi8opiuA8G3O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tarfile\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1flSPM8mPp",
        "outputId": "3aa010e7-4b64-40f8-b0a6-d2cf81ec3650"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "# Auto Download + Prepare VWW (10k subset)\n",
        "# ----------------------------\n",
        "vww_url = \"https://www.silabs.com/public/files/github/machine_learning/benchmarks/datasets/vw_coco2014_96.tar.gz\"\n",
        "\n",
        "base_dir = Path(\"/content/vww_work\")\n",
        "archive_path = base_dir / \"vw_coco2014_96.tar.gz\"\n",
        "extract_dir = base_dir / \"extracted\"\n",
        "subset_dir = base_dir / \"vww_10k\"\n",
        "\n",
        "n_per_class = 5000\n",
        "val_ratio = 0.20\n",
        "\n",
        "random.seed(41)\n",
        "torch.manual_seed(41)\n",
        "\n",
        "def download_vww():\n",
        "    base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if archive_path.exists() and archive_path.stat().st_size > 0:\n",
        "        print(\"‚úÖ VWW archive already downloaded\")\n",
        "        return\n",
        "\n",
        "    print(\"‚¨áÔ∏è Downloading VWW archive...\")\n",
        "    urlretrieve(vww_url, archive_path)\n",
        "    print(\"‚úÖ Download complete:\", archive_path)\n",
        "\n",
        "def extract_vww():\n",
        "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if any(extract_dir.iterdir()):\n",
        "        print(\"‚úÖ VWW already extracted\")\n",
        "        return\n",
        "\n",
        "    print(\"üì¶ Extracting VWW archive...\")\n",
        "    with tarfile.open(archive_path, \"r:gz\") as tar:\n",
        "        tar.extractall(extract_dir)\n",
        "    print(\"‚úÖ Extraction complete:\", extract_dir)\n",
        "\n",
        "def find_vww_root():\n",
        "    for p in extract_dir.rglob(\"person\"):\n",
        "        if p.is_dir() and (p.parent / \"non_person\").is_dir():\n",
        "            return p.parent\n",
        "    raise RuntimeError(\"‚ùå Could not find 'person' and 'non_person' directories under extracted dataset\")\n",
        "\n",
        "def list_images(folder):\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "    return [p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "def make_vww_subset(src_root):\n",
        "    if (subset_dir / \"train\" / \"person\").is_dir() and (subset_dir / \"val\" / \"non_person\").is_dir():\n",
        "        print(\"‚úÖ VWW 10k subset already exists:\", subset_dir)\n",
        "        return\n",
        "\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        for c in [\"person\", \"non_person\"]:\n",
        "            (subset_dir / split / c).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    person_imgs = list_images(src_root / \"person\")\n",
        "    nonperson_imgs = list_images(src_root / \"non_person\")\n",
        "\n",
        "    if len(person_imgs) < n_per_class or len(nonperson_imgs) < n_per_class:\n",
        "        raise ValueError(\n",
        "            f\"‚ùå Not enough images:\\n\"\n",
        "            f\"person: {len(person_imgs)} (need {n_per_class})\\n\"\n",
        "            f\"non_person: {len(nonperson_imgs)} (need {n_per_class})\"\n",
        "        )\n",
        "\n",
        "    random.shuffle(person_imgs)\n",
        "    random.shuffle(nonperson_imgs)\n",
        "\n",
        "    person_sel = person_imgs[:n_per_class]\n",
        "    nonperson_sel = nonperson_imgs[:n_per_class]\n",
        "\n",
        "    def split_list(lst, val_ratio):\n",
        "        n_val = int(len(lst) * val_ratio)\n",
        "        return lst[n_val:], lst[:n_val]  # train, val\n",
        "\n",
        "    p_train, p_val = split_list(person_sel, val_ratio)\n",
        "    n_train, n_val = split_list(nonperson_sel, val_ratio)\n",
        "\n",
        "    def copy_files(files, dst_dir):\n",
        "        for f in files:\n",
        "            dst = dst_dir / f.name\n",
        "            if dst.exists():\n",
        "                dst = dst_dir / (f\"{f.parent.name}_{f.name}\")\n",
        "            shutil.copy2(f, dst)\n",
        "\n",
        "    print(\"üß© Creating VWW 10k subset...\")\n",
        "    copy_files(p_train, subset_dir / \"train\" / \"person\")\n",
        "    copy_files(p_val,   subset_dir / \"val\"   / \"person\")\n",
        "    copy_files(n_train, subset_dir / \"train\" / \"non_person\")\n",
        "    copy_files(n_val,   subset_dir / \"val\"   / \"non_person\")\n",
        "    print(\"‚úÖ VWW subset created at:\", subset_dir)\n",
        "\n",
        "download_vww()\n",
        "extract_vww()\n",
        "vww_root = find_vww_root()\n",
        "print(\"‚úÖ Found VWW root:\", vww_root)\n",
        "make_vww_subset(vww_root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xfu0a3w8pnF",
        "outputId": "b7401b76-5cab-4de0-8780-6a5fe50da2c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ VWW archive already downloaded\n",
            "‚úÖ VWW already extracted\n",
            "‚úÖ Found VWW root: /content/vww_work/extracted/vw_coco2014_96\n",
            "‚úÖ VWW 10k subset already exists: /content/vww_work/vww_10k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Data Loaders (same style)\n",
        "# ----------------------------\n",
        "batch_size = 64\n",
        "img_size = 96\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                         (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                         (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=str(subset_dir / \"train\"), transform=train_transform)\n",
        "test_data  = datasets.ImageFolder(root=str(subset_dir / \"val\"),   transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Class mapping:\", train_data.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYA-BFGu8vF_",
        "outputId": "aa1d8571-a26e-499a-e708-7efdd6d16ec5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class mapping: {'non_person': 0, 'person': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Teacher Model (same style as your VWWConvNet)\n",
        "# ----------------------------\n",
        "class VWWConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 96 -> 48\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 48 -> 24\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 24 -> 12\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 12 -> 6\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.training:\n",
        "            x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "t1eHtEQS8w_r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Teacher weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "teacher = VWWConvNet().to(device)\n",
        "\n",
        "teacher.load_state_dict(torch.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/stm_vww_best.pth\",\n",
        "    map_location=torch.device(\"cpu\")\n",
        "))\n",
        "teacher.eval()\n",
        "print(\"‚úÖ Loaded Teacher: stm_vww_best.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9WkNjuF8yz9",
        "outputId": "52062feb-9fb5-4060-9071-23af56ca9e5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded Teacher: stm_vww_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Student Model (Smaller) - keep simple\n",
        "# ----------------------------\n",
        "class StudentVWWNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # 96 -> 48 -> 24 with 2 pools\n",
        "        self.fc1 = nn.Linear(32 * 24 * 24, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "zb_XJPVu809W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = StudentVWWNet().to(device)"
      ],
      "metadata": {
        "id": "Yyekgbaa9W1M"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Optimizer\n",
        "# ----------------------------\n",
        "optimizer = torch.optim.Adam(student.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "gAexo10u83aC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kd_loss(student_logits, teacher_logits, labels, T=4, alpha=0.3):\n",
        "    p = F.log_softmax(student_logits / T, dim=1)\n",
        "    q = F.softmax(teacher_logits / T, dim=1)\n",
        "    loss_kd = F.kl_div(p, q, reduction='batchmean') * (T * T)\n",
        "\n",
        "    loss_ce = F.cross_entropy(student_logits, labels)\n",
        "\n",
        "    return alpha * loss_ce + (1 - alpha) * loss_kd"
      ],
      "metadata": {
        "id": "QFQLlfZO857y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            out = model(X)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "9-l29Onw88L0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_teacher = evaluate(teacher, test_loader)\n",
        "print(f\"üéì Teacher Model Accuracy: {acc_teacher:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPn7bJqu8-V-",
        "outputId": "3af0e490-04e0-447a-b57f-639978e319f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéì Teacher Model Accuracy: 78.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Student Training (KD)\n",
        "# ----------------------------\n",
        "epochs = 30\n",
        "start_time = time.time()\n",
        "\n",
        "best_acc = 0.0\n",
        "best_epoch = 1\n",
        "best_path = \"/content/drive/My Drive/Colab Notebooks/stm_vww_kd_best.pth\"\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    student.train()\n",
        "    train_losses = 0.0\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        student_logits = student(X)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher(X)\n",
        "\n",
        "        loss = kd_loss(student_logits, teacher_logits, y, T=4, alpha=0.3)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses += loss.item()\n",
        "\n",
        "    acc = evaluate(student, test_loader)\n",
        "    print(f\"Epoch {epoch} / {epochs} | Loss: {train_losses / len(train_loader):.4f} | Student Test Acc: {acc:.2f}%\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_epoch = epoch\n",
        "        torch.save(student.state_dict(), best_path)\n",
        "        print(\"‚úÖ Student best saved as stm_vww_kd_best.pth for epoch\", best_epoch)\n",
        "\n",
        "print(f\"Training time: {(time.time() - start_time)/60:.2f} minutes\")\n",
        "print(f\"Best epoch: {best_epoch} | Best Student Test Acc: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEXlEvlT9A1A",
        "outputId": "8b483748-fdc4-4e37-d57b-9873ad9c53aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 30 | Loss: 0.4397 | Student Test Acc: 68.85%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 1\n",
            "Epoch 2 / 30 | Loss: 0.4204 | Student Test Acc: 69.35%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 2\n",
            "Epoch 3 / 30 | Loss: 0.4136 | Student Test Acc: 70.15%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 3\n",
            "Epoch 4 / 30 | Loss: 0.4013 | Student Test Acc: 69.30%\n",
            "Epoch 5 / 30 | Loss: 0.3937 | Student Test Acc: 65.70%\n",
            "Epoch 6 / 30 | Loss: 0.3847 | Student Test Acc: 68.30%\n",
            "Epoch 7 / 30 | Loss: 0.3734 | Student Test Acc: 69.95%\n",
            "Epoch 8 / 30 | Loss: 0.3819 | Student Test Acc: 68.55%\n",
            "Epoch 9 / 30 | Loss: 0.3645 | Student Test Acc: 68.70%\n",
            "Epoch 10 / 30 | Loss: 0.3554 | Student Test Acc: 69.80%\n",
            "Epoch 11 / 30 | Loss: 0.3517 | Student Test Acc: 69.70%\n",
            "Epoch 12 / 30 | Loss: 0.3504 | Student Test Acc: 70.65%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 12\n",
            "Epoch 13 / 30 | Loss: 0.3430 | Student Test Acc: 69.70%\n",
            "Epoch 14 / 30 | Loss: 0.3472 | Student Test Acc: 69.60%\n",
            "Epoch 15 / 30 | Loss: 0.3498 | Student Test Acc: 71.40%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 15\n",
            "Epoch 16 / 30 | Loss: 0.3388 | Student Test Acc: 70.00%\n",
            "Epoch 17 / 30 | Loss: 0.3422 | Student Test Acc: 69.50%\n",
            "Epoch 18 / 30 | Loss: 0.3317 | Student Test Acc: 70.40%\n",
            "Epoch 19 / 30 | Loss: 0.3299 | Student Test Acc: 69.65%\n",
            "Epoch 20 / 30 | Loss: 0.3247 | Student Test Acc: 70.10%\n",
            "Epoch 21 / 30 | Loss: 0.3312 | Student Test Acc: 70.75%\n",
            "Epoch 22 / 30 | Loss: 0.3223 | Student Test Acc: 71.80%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 22\n",
            "Epoch 23 / 30 | Loss: 0.3211 | Student Test Acc: 71.45%\n",
            "Epoch 24 / 30 | Loss: 0.3093 | Student Test Acc: 69.50%\n",
            "Epoch 25 / 30 | Loss: 0.3173 | Student Test Acc: 71.20%\n",
            "Epoch 26 / 30 | Loss: 0.3101 | Student Test Acc: 67.50%\n",
            "Epoch 27 / 30 | Loss: 0.3128 | Student Test Acc: 70.05%\n",
            "Epoch 28 / 30 | Loss: 0.3116 | Student Test Acc: 71.15%\n",
            "Epoch 29 / 30 | Loss: 0.3065 | Student Test Acc: 69.35%\n",
            "Epoch 30 / 30 | Loss: 0.2985 | Student Test Acc: 72.00%\n",
            "‚úÖ Student best saved as stm_vww_kd_best.pth for epoch 30\n",
            "Training time: 8.47 minutes\n",
            "Best epoch: 30 | Best Student Test Acc: 72.00%\n"
          ]
        }
      ]
    }
  ]
}