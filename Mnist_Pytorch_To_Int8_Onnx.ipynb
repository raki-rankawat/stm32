{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsA10hy6c/V1iZIVHbk2dv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/Mnist_Pytorch_To_Int8_Onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "WKWZfTfskJXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd08336-8686-4098-c31d-1ae5566595de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TZfzVc-Nhw_7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX + ORT quantization\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType, QuantFormat, CalibrationDataReader"
      ],
      "metadata": {
        "id": "9ZN1aiFGiTTc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Variables & Utils\n",
        "# -----------------------\n",
        "\n",
        "batch_size=64\n",
        "epochs = 5\n",
        "\n",
        "def total_time_minutes(start_time):\n",
        "  return (time.time() - start_time) / 60"
      ],
      "metadata": {
        "id": "3hqPQK0coU0c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Data Loaders\n",
        "# -----------------------\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_transform = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_transform = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_transform, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_transform, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Szl3CK8hMows",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f5910f-ecc0-4744-977d-d09e7719dc3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.57MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.15MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "class MNISTTinyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1) # 28 -> 26\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1) # 13 -> 11\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2) # 28 -> 14\n",
        "\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2) # 14 -> 7\n",
        "\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x) # logits\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "udq2NlbAlSPA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Random Seeds and Model Instance\n",
        "# -----------------------\n",
        "torch.manual_seed(41)\n",
        "model = MNISTTinyCNN()"
      ],
      "metadata": {
        "id": "xGLfldEsNKJk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Loss & Optimizer\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hpRt8jInNLfm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Training\n",
        "# -----------------------\n",
        "def train(epoch, model, train_loader, criterian, optimizer, log_every=600):\n",
        "  model.train()\n",
        "  trn_corr = 0\n",
        "  last_loss = None\n",
        "\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterian(y_pred, y_train)\n",
        "    last_loss = loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    predicted = y_pred.argmax(dim=1)\n",
        "    trn_corr += (predicted == y_train).sum().item()\n",
        "\n",
        "    if b % log_every == 0:\n",
        "      seen = b * len(X_train)\n",
        "      total = len(train_loader.dataset)\n",
        "      pct = 100.0 * b / len(train_loader)\n",
        "      print(f\"Epoch {epoch+1} [{seen}/{total} ({pct:.0f}%)]  Loss: {last_loss:.6f}\")\n",
        "\n",
        "  tran_acc = trn_corr / len(train_loader.dataset)\n",
        "  return last_loss, tran_acc"
      ],
      "metadata": {
        "id": "IaoMHa-ZownB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accs = []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(epoch, model, train_loader, criterion, optimizer)\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  train_accs.append(train_acc)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "print(f\"Time taken: {total_time_minutes(start_time)} minutes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbD4-ObHNx57",
        "outputId": "74f4a182-c992-4281-c1d0-6d5b28e5c727"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 [0/60000 (0%)]  Loss: 2.307117\n",
            "Epoch 1 [38400/60000 (64%)]  Loss: 0.090759\n",
            "Epoch 1/5 | Train Loss: 0.1874 | Train Acc: 0.8975\n",
            "Epoch 2 [0/60000 (0%)]  Loss: 0.204284\n",
            "Epoch 2 [38400/60000 (64%)]  Loss: 0.060426\n",
            "Epoch 2/5 | Train Loss: 0.1256 | Train Acc: 0.9702\n",
            "Epoch 3 [0/60000 (0%)]  Loss: 0.013219\n",
            "Epoch 3 [38400/60000 (64%)]  Loss: 0.052907\n",
            "Epoch 3/5 | Train Loss: 0.0080 | Train Acc: 0.9791\n",
            "Epoch 4 [0/60000 (0%)]  Loss: 0.046314\n",
            "Epoch 4 [38400/60000 (64%)]  Loss: 0.019896\n",
            "Epoch 4/5 | Train Loss: 0.0689 | Train Acc: 0.9834\n",
            "Epoch 5 [0/60000 (0%)]  Loss: 0.064024\n",
            "Epoch 5 [38400/60000 (64%)]  Loss: 0.033091\n",
            "Epoch 5/5 | Train Loss: 0.0030 | Train Acc: 0.9865\n",
            "Time taken: 1.5691192150115967 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Testing\n",
        "# -----------------------\n",
        "def test(model, test_loader, criterian):\n",
        "  model.eval()\n",
        "  test_corr = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "\n",
        "  for X_test, y_test in test_loader:\n",
        "    y_val = model(X_test)\n",
        "    loss = criterian(y_val, y_test)\n",
        "\n",
        "    total_loss += loss.item() * y_test.size(0)\n",
        "    total += y_test.size(0)\n",
        "\n",
        "    predicted = y_val.argmax(dim=1)\n",
        "    test_corr += (predicted == y_test).sum().item()\n",
        "\n",
        "  test_loss = total_loss / total\n",
        "  test_acc = test_corr / total\n",
        "\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "hH4Pknv5iCGg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses = []\n",
        "test_accs = []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  test_loss, test_acc = test(model, test_loader, criterion)\n",
        "\n",
        "  test_losses.append(test_loss)\n",
        "  test_accs.append(test_acc)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{epochs} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(f\"Time taken: {total_time_minutes(start_time)} minutes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq59cYsrOB0e",
        "outputId": "4cf8e719-d4fc-4b3b-9624-8f11957f4f1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Test Loss: 0.0370 | Test Acc: 0.9883\n",
            "Epoch 2/5 | Test Loss: 0.0370 | Test Acc: 0.9883\n",
            "Epoch 3/5 | Test Loss: 0.0370 | Test Acc: 0.9883\n",
            "Epoch 4/5 | Test Loss: 0.0370 | Test Acc: 0.9883\n",
            "Epoch 5/5 | Test Loss: 0.0370 | Test Acc: 0.9883\n",
            "Time taken: 0.1804893453915914 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# STM32 Pipeline\n",
        "# -----------------------\n",
        "def export_onnx(model, onnx_path):\n",
        "  model.eval()\n",
        "\n",
        "  dummy = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "  torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        export_params=True,\n",
        "        opset_version=18,\n",
        "        do_constant_folding=True,\n",
        "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "        dynamo=False\n",
        "    )\n",
        "  onnx.checker.check_model(onnx_path, full_check=False)\n",
        "  print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "export_onnx(model, \"mnist_lenet_fp32.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-gR8mIDPXq4",
        "outputId": "e2708f2c-5d84-46d9-e92c-ef76fb09c358"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model saved to: mnist_lenet_fp32.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1940908235.py:9: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/torchscript_exporter/utils.py:1903: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 20 MNIST test images\n",
        "# -----------------------\n",
        "test = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "N = 20\n",
        "\n",
        "# Inputs in NHWC float32 (matches ST log format)\n",
        "x = np.zeros((N, 28, 28, 1), dtype=np.float32)\n",
        "for i in range(N):\n",
        "    img, _ = test[i]\n",
        "    x[i, :, :, 0] = img.squeeze(0).numpy()\n",
        "\n",
        "# Save INPUTS ONLY\n",
        "np.savez(\"mnist_20.npz\", input=x)\n",
        "\n",
        "print(\"Saved mnist_20.npz with keys:\", np.load(\"mnist_20.npz\").files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8xsWJbxGFCH",
        "outputId": "37576fae-f9d2-47d7-df47-1694397a251e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved mnist_20.npz with keys: ['input']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantization"
      ],
      "metadata": {
        "id": "0AC_w6JcW6HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Load MNIST (NO normalization for now; matches what you already ran)\n",
        "# -----------------------\n",
        "test_loader_quant = DataLoader(test_transform, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "faD22MhmW8e5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Load trained weights\n",
        "# -----------------------\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De9YnSDSXfYJ",
        "outputId": "07b89047-90d3-4cb5-b2d4-10f55227db75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTTinyCNN(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Collect N samples\n",
        "# -----------------------\n",
        "N = 200\n",
        "inputs_nhwc = []\n",
        "logits = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (x, y) in enumerate(test_loader_quant):\n",
        "    if i >= N:\n",
        "      break\n",
        "\n",
        "    out = model(x)\n",
        "    # convert input to NHWC (1x28x28x1)\n",
        "    x_nhwc = x.numpy().transpose(0, 2, 3, 1).astype(np.float32)\n",
        "    inputs_nhwc.append(x_nhwc[0])\n",
        "    logits.append(out.numpy()[0].astype(np.float32))\n",
        "    labels.append(int(y.item()))\n",
        "\n",
        "inputs_nhwc = np.stack(inputs_nhwc, axis=0)\n",
        "logits = np.stack(logits, axis=0)\n",
        "labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "print(\"Inputs:\", inputs_nhwc.shape, inputs_nhwc.dtype)\n",
        "print(\"Logits:\", logits.shape, logits.dtype)\n",
        "print(\"Labels:\", labels.shape, logits.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L_764WpXkbe",
        "outputId": "0aa6b74f-6de9-4dad-e1e5-a92827455808"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: (200, 28, 28, 1) float32\n",
            "Logits: (200, 10) float32\n",
            "Labels: (200,) float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Save files\n",
        "# -----------------------\n",
        "# 1) Calibration file (inputs only)\n",
        "np.savez(\"mnist_calib_200.npz\", input=inputs_nhwc)\n",
        "\n",
        "# 2) Validation file for stedgeai: input + ONE output array\n",
        "# Use name \"logits\" OR \"output\". If one fails, try the other.\n",
        "np.savez(\"mnist_val_200_io.npz\", input=inputs_nhwc, logits=logits)\n",
        "\n",
        "# 3) Labels saved separately (for accuracy in Python)\n",
        "np.savez(\"mnist_labels_200.npz\", label=labels)"
      ],
      "metadata": {
        "id": "JK5mhJTeY6q1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load logits (reference outputs) and labels (ground truth)\n",
        "# val = np.load(\"mnist_val_200_io.npz\")\n",
        "# lab = np.load(\"mnist_labels_200.npz\")\n",
        "\n",
        "# logits = val[\"logits\"]          # shape (200, 10)\n",
        "# labels = lab[\"label\"]           # shape (200,)\n",
        "\n",
        "# # predicted class = argmax over 10 logits\n",
        "# pred = np.argmax(logits, axis=1)\n",
        "\n",
        "# acc = (pred == labels).mean() * 100.0\n",
        "# print(f\"Accuracy on these 200 samples: {acc:.2f}%\")\n",
        "\n",
        "# # optional: confusion matrix\n",
        "# cm = np.zeros((10, 10), dtype=int)\n",
        "# for y, p in zip(labels, pred):\n",
        "#     cm[y, p] += 1\n",
        "# print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "# print(cm)"
      ],
      "metadata": {
        "id": "tlzHEZ-P8IbK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "val = np.load(\"mnist_val_200_io.npz\")\n",
        "labels = np.load(\"mnist_labels_200.npz\")[\"label\"]\n",
        "\n",
        "out = np.load(\"network_val_io.npz\")\n",
        "logits = out[\"c_outputs_1\"].reshape(len(labels), 10)\n",
        "\n",
        "acc = (np.argmax(logits, axis=1) == labels).mean()\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdaoU1sy85jC",
        "outputId": "3ee4f797-f734-42bb-f7b3-897126ede5e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 0.99\n"
          ]
        }
      ]
    }
  ]
}