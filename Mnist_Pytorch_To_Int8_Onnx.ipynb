{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuRXC8qNRj0r5ugFdWmtOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/Mnist_Pytorch_To_Int8_Onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "WKWZfTfskJXN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TZfzVc-Nhw_7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX + ORT quantization\n",
        "# import onnx\n",
        "# import onnxruntime as ort\n",
        "\n",
        "# from onnxruntime.quantization import quantize_dynamic, QuantType, QuantFormat, CalibrationDataReader"
      ],
      "metadata": {
        "id": "9ZN1aiFGiTTc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Data Loaders\n",
        "# -----------------------\n",
        "batch_size = 64\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_transform = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_transform = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_transform, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_transform, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Szl3CK8hMows"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "class MNISTTinyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1) # 28 -> 26\n",
        "    self.conv2 = nn.Conv2d(6, 18, 3, 1) # 13 -> 11\n",
        "    self.fc1 = nn.Linear(18 * 5 * 5, 150)\n",
        "    self.fc2 = nn.Linear(150, 50)\n",
        "    self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2) # 28 - 2 / 2 -> 13\n",
        "\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2) # 13 - 2 / 2 -> 5\n",
        "\n",
        "    x = x.view(-1, 18 * 5 * 5)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x) # logits\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "udq2NlbAlSPA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Random Seeds and Model Instance\n",
        "# -----------------------\n",
        "torch.manual_seed(41)\n",
        "model = MNISTTinyCNN()"
      ],
      "metadata": {
        "id": "xGLfldEsNKJk"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Loss & Optimizer\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hpRt8jInNLfm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Training\n",
        "# -----------------------\n",
        "def train(epoch, model, loader, criterion, optimizer, log_every=600):\n",
        "  model.train() # training mode\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  for b, (X, y) in enumerate(loader):\n",
        "\n",
        "    # Forward\n",
        "    outputs = model(X)\n",
        "\n",
        "    # Loss\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Metrics\n",
        "    running_loss += loss.item()\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    correct += (preds == y).sum().item()\n",
        "    total += y.size(0)\n",
        "\n",
        "    # Print out results\n",
        "    # if b % 600 == 0:\n",
        "    #   print(f\"Epoch {epoch} finished | Avg loss so far = {running_loss / len(loader):.4f}\")\n",
        "\n",
        "  avg_loss = running_loss / len(loader)\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "IaoMHa-ZownB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Testing\n",
        "# -----------------------\n",
        "def test(model, loader, criterion):\n",
        "  model.eval() # testing mode\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in loader:\n",
        "      # Forward\n",
        "      outputs = model(X)\n",
        "\n",
        "      # Loss\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      # Metrics\n",
        "      running_loss += loss.item()\n",
        "      preds = outputs.argmax(dim=1)\n",
        "      correct += (preds == y).sum().item()\n",
        "      total += y.size(0)\n",
        "\n",
        "  avg_loss = running_loss / len(loader)\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "hH4Pknv5iCGg"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  train_loss, train_acc = train(epoch, model, train_loader, criterion, optimizer)\n",
        "  test_loss, test_acc = test(model, test_loader, criterion)\n",
        "\n",
        "  print(\n",
        "      f\"Epoch {epoch}/{epochs} | \"\n",
        "      f\"Train loss: {train_loss:.4f}, Train acc: {train_acc*100:.2f}% | \"\n",
        "      f\"Test loss: {test_loss:.4f}, Test acc: {test_acc*100:.2f}%\"\n",
        "  )\n",
        "\n",
        "print(f\"Time taken: {(time.time() - start_time) / 60} minutes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq59cYsrOB0e",
        "outputId": "d657082c-e705-455a-f025-d4506f52403c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train loss: 0.0379, Train acc: 98.75% | Test loss: 0.0470, Test acc: 98.52%\n",
            "Epoch 2/5 | Train loss: 0.0322, Train acc: 98.99% | Test loss: 0.0337, Test acc: 98.94%\n",
            "Epoch 3/5 | Train loss: 0.0270, Train acc: 99.11% | Test loss: 0.0355, Test acc: 98.79%\n",
            "Epoch 4/5 | Train loss: 0.0238, Train acc: 99.22% | Test loss: 0.0367, Test acc: 98.83%\n",
            "Epoch 5/5 | Train loss: 0.0197, Train acc: 99.33% | Test loss: 0.0399, Test acc: 98.87%\n",
            "Time taken: 1.7040016889572143 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # STM32 Pipeline\n",
        "# # -----------------------\n",
        "# def export_onnx(model, onnx_path):\n",
        "#   model.eval()\n",
        "\n",
        "#   dummy = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "#   torch.onnx.export(\n",
        "#         model,\n",
        "#         dummy,\n",
        "#         onnx_path,\n",
        "#         input_names=[\"input\"],\n",
        "#         output_names=[\"logits\"],\n",
        "#         export_params=True,\n",
        "#         opset_version=18,\n",
        "#         do_constant_folding=True,\n",
        "#         dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "#         dynamo=False\n",
        "#     )\n",
        "#   onnx.checker.check_model(onnx_path, full_check=False)\n",
        "#   print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "# export_onnx(model, \"mnist_lenet_fp32.onnx\")"
      ],
      "metadata": {
        "id": "f-gR8mIDPXq4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # 20 MNIST test images\n",
        "# # -----------------------\n",
        "# test = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# N = 20\n",
        "\n",
        "# # Inputs in NHWC float32 (matches ST log format)\n",
        "# x = np.zeros((N, 28, 28, 1), dtype=np.float32)\n",
        "# for i in range(N):\n",
        "#     img, _ = test[i]\n",
        "#     x[i, :, :, 0] = img.squeeze(0).numpy()\n",
        "\n",
        "# # Save INPUTS ONLY\n",
        "# np.savez(\"mnist_20.npz\", input=x)\n",
        "\n",
        "# print(\"Saved mnist_20.npz with keys:\", np.load(\"mnist_20.npz\").files)"
      ],
      "metadata": {
        "id": "M8xsWJbxGFCH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantization"
      ],
      "metadata": {
        "id": "0AC_w6JcW6HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # Load MNIST (NO normalization for now; matches what you already ran)\n",
        "# # -----------------------\n",
        "# test_loader_quant = DataLoader(test_transform, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "faD22MhmW8e5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # Load trained weights\n",
        "# # -----------------------\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "De9YnSDSXfYJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # Collect N samples\n",
        "# # -----------------------\n",
        "# N = 200\n",
        "# inputs_nhwc = []\n",
        "# logits = []\n",
        "# labels = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   for i, (x, y) in enumerate(test_loader_quant):\n",
        "#     if i >= N:\n",
        "#       break\n",
        "\n",
        "#     out = model(x)\n",
        "#     # convert input to NHWC (1x28x28x1)\n",
        "#     x_nhwc = x.numpy().transpose(0, 2, 3, 1).astype(np.float32)\n",
        "#     inputs_nhwc.append(x_nhwc[0])\n",
        "#     logits.append(out.numpy()[0].astype(np.float32))\n",
        "#     labels.append(int(y.item()))\n",
        "\n",
        "# inputs_nhwc = np.stack(inputs_nhwc, axis=0)\n",
        "# logits = np.stack(logits, axis=0)\n",
        "# labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "# print(\"Inputs:\", inputs_nhwc.shape, inputs_nhwc.dtype)\n",
        "# print(\"Logits:\", logits.shape, logits.dtype)\n",
        "# print(\"Labels:\", labels.shape, logits.dtype)"
      ],
      "metadata": {
        "id": "8L_764WpXkbe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------\n",
        "# # Save files\n",
        "# # -----------------------\n",
        "# # 1) Calibration file (inputs only)\n",
        "# np.savez(\"mnist_calib_200.npz\", input=inputs_nhwc)\n",
        "\n",
        "# # 2) Validation file for stedgeai: input + ONE output array\n",
        "# # Use name \"logits\" OR \"output\". If one fails, try the other.\n",
        "# np.savez(\"mnist_val_200_io.npz\", input=inputs_nhwc, logits=logits)\n",
        "\n",
        "# # 3) Labels saved separately (for accuracy in Python)\n",
        "# np.savez(\"mnist_labels_200.npz\", label=labels)"
      ],
      "metadata": {
        "id": "JK5mhJTeY6q1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val = np.load(\"mnist_val_200_io.npz\")\n",
        "# labels = np.load(\"mnist_labels_200.npz\")[\"label\"]\n",
        "\n",
        "# out = np.load(\"network_val_io.npz\")\n",
        "# logits = out[\"c_outputs_1\"].reshape(len(labels), 10)\n",
        "\n",
        "# acc = (np.argmax(logits, axis=1) == labels).mean()\n",
        "# print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "id": "rdaoU1sy85jC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d = np.load(\"mnist_calib_200.npz\")\n",
        "# print(d.files)\n",
        "# x = d[\"input\"]\n",
        "# print(x.shape, x.dtype, x.min(), x.max())"
      ],
      "metadata": {
        "id": "4jso3g9ZboGa"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inp = r\"mnist_lenet_fp32.onnx\"\n",
        "# out = r\"mnist_lenet_int8_dynamic.onnx\"\n",
        "\n",
        "# quantize_dynamic(\n",
        "#     model_input=inp,\n",
        "#     model_output=out,\n",
        "#     weight_type=QuantType.QInt8\n",
        "# )\n",
        "\n",
        "# print(\"Saved:\", out)\n"
      ],
      "metadata": {
        "id": "F3jfPdSNsQXd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from onnxruntime.quantization import (\n",
        "#     quantize_static, CalibrationDataReader,\n",
        "#     QuantFormat, QuantType\n",
        "# )\n",
        "\n",
        "# class MNISTCalibReader(CalibrationDataReader):\n",
        "#     def __init__(self, npz_path, input_name=\"input\"):\n",
        "#         d = np.load(npz_path)\n",
        "#         x = d[input_name].astype(np.float32)          # likely (N,28,28,1)\n",
        "\n",
        "#         # If NHWC, convert to NCHW expected by your ONNX model\n",
        "#         if x.ndim == 4 and x.shape[-1] == 1:         # (N,28,28,1)\n",
        "#             x = np.transpose(x, (0, 3, 1, 2))         # -> (N,1,28,28)\n",
        "\n",
        "#         self.x = x\n",
        "#         self.input_name = input_name\n",
        "#         self.i = 0\n",
        "\n",
        "#     def get_next(self):\n",
        "#         if self.i >= len(self.x):\n",
        "#             return None\n",
        "#         batch = self.x[self.i:self.i+1]              # (1,1,28,28)\n",
        "#         self.i += 1\n",
        "#         return {self.input_name: batch}\n",
        "\n",
        "# inp   = r\"mnist_lenet_fp32.onnx\"\n",
        "# calib = r\"mnist_calib_200.npz\"\n",
        "# out   = r\"mnist_lenet_int8_static_qdq.onnx\"\n",
        "\n",
        "# reader = MNISTCalibReader(calib, input_name=\"input\")\n",
        "\n",
        "# quantize_static(\n",
        "#     model_input=inp,\n",
        "#     model_output=out,\n",
        "#     calibration_data_reader=reader,\n",
        "#     quant_format=QuantFormat.QDQ,     # important for compiler friendliness\n",
        "#     activation_type=QuantType.QInt8,\n",
        "#     weight_type=QuantType.QInt8,\n",
        "#     per_channel=True,\n",
        "# )\n",
        "\n",
        "# print(\"Saved:\", out)"
      ],
      "metadata": {
        "id": "vAu1WJhKuu1C"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-quantize"
      ],
      "metadata": {
        "id": "OlBi0RlexqIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 1) Create a FLOAT calibration NPZ in NCHW\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# d = np.load(r\"mnist_calib_200.npz\")\n",
        "# x = d[\"input\"].astype(np.float32)  # currently NHWC (N,28,28,1)\n",
        "\n",
        "# x = np.transpose(x, (0,3,1,2))     # -> NCHW (N,1,28,28)\n",
        "\n",
        "# np.savez(r\"mnist_calib_200_nchw_fp32.npz\", input=x)\n",
        "# print(x.shape, x.dtype, x.min(), x.max())"
      ],
      "metadata": {
        "id": "mkTgwm9qxsk8"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 2) Quantize again with QDQ, but donâ€™t let ORT change IO types\n",
        "\n",
        "# import numpy as np\n",
        "# from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantFormat, QuantType\n",
        "\n",
        "# class CalibReader(CalibrationDataReader):\n",
        "#     def __init__(self, npz_path, input_name=\"input\"):\n",
        "#         self.x = np.load(npz_path)[input_name].astype(np.float32)  # (N,1,28,28)\n",
        "#         self.input_name = input_name\n",
        "#         self.i = 0\n",
        "\n",
        "#     def get_next(self):\n",
        "#         if self.i >= len(self.x):\n",
        "#             return None\n",
        "#         batch = self.x[self.i:self.i+1]  # (1,1,28,28)\n",
        "#         self.i += 1\n",
        "#         return {self.input_name: batch}\n",
        "\n",
        "# inp   = r\"mnist_lenet_fp32.onnx\"\n",
        "# calib = r\"mnist_calib_200_nchw_fp32.npz\"\n",
        "# out   = r\"mnist_lenet_int8_static_qdq_floatio.onnx\"\n",
        "\n",
        "# reader = CalibReader(calib, \"input\")\n",
        "\n",
        "# quantize_static(\n",
        "#     model_input=inp,\n",
        "#     model_output=out,\n",
        "#     calibration_data_reader=reader,\n",
        "#     quant_format=QuantFormat.QDQ,\n",
        "#     activation_type=QuantType.QInt8,\n",
        "#     weight_type=QuantType.QInt8,\n",
        "#     per_channel=True,\n",
        "# )\n",
        "\n",
        "# print(\"Saved:\", out)"
      ],
      "metadata": {
        "id": "ENH3GV3Yx5fz"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 3) Verify the new ONNX input type is float\n",
        "\n",
        "# import onnx\n",
        "# m = onnx.load(r\"mnist_lenet_int8_static_qdq_floatio.onnx\")\n",
        "# t = m.graph.input[0].type.tensor_type\n",
        "# print(\"input elem type:\", t.elem_type)  # should correspond to float"
      ],
      "metadata": {
        "id": "e9xmFp9KyCE7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # labels from your dataset creation step\n",
        "# labels = np.load(\"mnist_labels_200.npz\")[\"label\"]  # shape (200,)\n",
        "\n",
        "# # outputs produced by stedgeai validate\n",
        "# out = np.load(r\"network_val_io.npz\")\n",
        "\n",
        "# # int8 outputs from the board, shape (200,1,1,10)\n",
        "# c = out[\"c_outputs_1\"].astype(np.float32).reshape(len(labels), 10)\n",
        "\n",
        "# # dequantize using values printed in your log\n",
        "# scale = 0.165920198\n",
        "# zp = 18\n",
        "# logits = (c - zp) * scale\n",
        "\n",
        "# pred = np.argmax(logits, axis=1)\n",
        "# acc = (pred == labels).mean()\n",
        "# print(\"STM32 INT8 accuracy:\", acc)"
      ],
      "metadata": {
        "id": "MxSRmkXW3DDx"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}