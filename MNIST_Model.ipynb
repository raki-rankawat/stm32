{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlwjLIQ8aMxg28e02a1EYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/MNIST_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trained Model"
      ],
      "metadata": {
        "id": "lPCiPfQGj4ST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yz1X4DTgjxSv"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 64\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_transform = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_transform = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_transform, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_transform, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2bq-7zpkI69",
        "outputId": "2fdef643-b7b0-4c7e-d767-a7fb2ae25ae5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 335kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.14MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.00MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "class MNISTTinyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, padding=1)\n",
        "    self.fc1 = nn.Linear(16 * 7 * 7, 196)\n",
        "    self.fc2 = nn.Linear(196, 49)\n",
        "    self.fc3 = nn.Linear(49, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2) # 28 / 2 -> 14\n",
        "\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2) # 14 / 2 -> 7\n",
        "\n",
        "    x = x.view(x.size(0), -1) # Flatten\n",
        "\n",
        "    x = F.relu(self.fc1(x)) # 784 -> 196\n",
        "    x = F.relu(self.fc2(x)) # 196 -> 49\n",
        "    x = self.fc3(x) # 49 -> 10 (logits)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "J6kpXH94kOlp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Seeds and Model Instance\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(41)\n",
        "model = MNISTTinyCNN().to(device)"
      ],
      "metadata": {
        "id": "zoo1al4dnR2L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3bZh7NUlnVQX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train(epoch, model, loader, criterion, optimizer):\n",
        "  model.train() # training mode\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  for b, (X, y) in enumerate(loader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Forward\n",
        "    outputs = model(X)\n",
        "\n",
        "    # Loss\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Metrics\n",
        "    batch_size = y.size(0)\n",
        "    running_loss += loss.item() * batch_size\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    correct += (preds == y).sum().item()\n",
        "    total += batch_size\n",
        "\n",
        "  avg_loss = running_loss / total\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "LJsfhW6lnYLu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def test(model, loader, criterion):\n",
        "  model.eval() # testing mode\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in loader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # Forward\n",
        "      outputs = model(X)\n",
        "\n",
        "      # Loss\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      # Metrics\n",
        "      batch_size = y.size(0)\n",
        "      running_loss += loss.item() * batch_size\n",
        "      preds = outputs.argmax(dim=1)\n",
        "      correct += (preds == y).sum().item()\n",
        "      total += batch_size\n",
        "\n",
        "  avg_loss = running_loss / total\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "pn_TPtwRnbv5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  train_loss, train_acc = train(epoch, model, train_loader, criterion, optimizer)\n",
        "  test_loss, test_acc = test(model, test_loader, criterion)\n",
        "\n",
        "  print(\n",
        "      f\"Epoch {epoch}/{epochs} | \"\n",
        "      f\"Train loss: {train_loss:.4f}, Train acc: {train_acc*100:.2f}% | \"\n",
        "      f\"Test loss: {test_loss:.4f}, Test acc: {test_acc*100:.2f}%\"\n",
        "  )\n",
        "\n",
        "print(f\"Time taken: {(time.time() - start_time) / 60} minutes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT6740aKnful",
        "outputId": "d62f8d13-0782-4158-89d8-622d7329db71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train loss: 0.2322, Train acc: 93.04% | Test loss: 0.0706, Test acc: 97.73%\n",
            "Epoch 2/5 | Train loss: 0.0648, Train acc: 97.98% | Test loss: 0.0455, Test acc: 98.55%\n",
            "Epoch 3/5 | Train loss: 0.0451, Train acc: 98.59% | Test loss: 0.0325, Test acc: 98.84%\n",
            "Epoch 4/5 | Train loss: 0.0323, Train acc: 99.00% | Test loss: 0.0368, Test acc: 98.75%\n",
            "Epoch 5/5 | Train loss: 0.0264, Train acc: 99.15% | Test loss: 0.0389, Test acc: 98.88%\n",
            "Time taken: 2.6832316676775614 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVG4o78aomw4",
        "outputId": "064e6ac7-1117-40f8-f239-10d8e72fa5b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/stm_mnist_model.pth\")\n",
        "print(\"✅ Model saved as stm_mnist_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdcb5zD2ooxI",
        "outputId": "34d420dd-e6f0-4f9c-a676-b7cffc532aa2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved as stm_mnist_model.pth\n"
          ]
        }
      ]
    }
  ]
}