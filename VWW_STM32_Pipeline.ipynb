{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQYOliUo2W/+6G0KEER09t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raki-rankawat/stm32/blob/main/VWW_STM32_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6qMDz4SdJQz",
        "outputId": "aa40f365-a364-487f-8adb-946583d0b524"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import tarfile\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_static, QuantType, QuantFormat, CalibrationDataReader"
      ],
      "metadata": {
        "id": "a4DFgsVbdjTU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JnRQvA8dlre",
        "outputId": "131e209c-765d-4252-8ba0-18cd7cd41c45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Auto Download + Prepare VWW (10k subset)\n",
        "# ----------------------------\n",
        "vww_url = \"https://www.silabs.com/public/files/github/machine_learning/benchmarks/datasets/vw_coco2014_96.tar.gz\"\n",
        "\n",
        "base_dir = Path(\"/content/vww_work\")\n",
        "archive_path = base_dir / \"vw_coco2014_96.tar.gz\"\n",
        "extract_dir = base_dir / \"extracted\"\n",
        "subset_dir = base_dir / \"vww_10k\"\n",
        "\n",
        "# Subset config: 5k person + 5k non_person\n",
        "n_per_class = 5000\n",
        "val_ratio = 0.20\n",
        "\n",
        "random.seed(41)\n",
        "torch.manual_seed(41)\n",
        "\n",
        "def download_vww():\n",
        "    base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if archive_path.exists() and archive_path.stat().st_size > 0:\n",
        "        print(\"‚úÖ VWW archive already downloaded\")\n",
        "        return\n",
        "\n",
        "    print(\"‚¨áÔ∏è Downloading VWW archive...\")\n",
        "    urlretrieve(vww_url, archive_path)\n",
        "    print(\"‚úÖ Download complete:\", archive_path)\n",
        "\n",
        "def extract_vww():\n",
        "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if any(extract_dir.iterdir()):\n",
        "        print(\"‚úÖ VWW already extracted\")\n",
        "        return\n",
        "\n",
        "    print(\"üì¶ Extracting VWW archive...\")\n",
        "    with tarfile.open(archive_path, \"r:gz\") as tar:\n",
        "        tar.extractall(extract_dir)\n",
        "    print(\"‚úÖ Extraction complete:\", extract_dir)\n",
        "\n",
        "def find_vww_root():\n",
        "    # Find folder that contains BOTH person/ and non_person/\n",
        "    for p in extract_dir.rglob(\"person\"):\n",
        "        if p.is_dir() and (p.parent / \"non_person\").is_dir():\n",
        "            return p.parent\n",
        "    raise RuntimeError(\"‚ùå Could not find 'person' and 'non_person' directories under extracted dataset\")\n",
        "\n",
        "def list_images(folder):\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "    return [p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "def make_vww_subset(src_root):\n",
        "    # Skip if subset already exists\n",
        "    if (subset_dir / \"train\" / \"person\").is_dir() and (subset_dir / \"val\" / \"non_person\").is_dir():\n",
        "        print(\"‚úÖ VWW 10k subset already exists:\", subset_dir)\n",
        "        return\n",
        "\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        for c in [\"person\", \"non_person\"]:\n",
        "            (subset_dir / split / c).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    person_imgs = list_images(src_root / \"person\")\n",
        "    nonperson_imgs = list_images(src_root / \"non_person\")\n",
        "\n",
        "    if len(person_imgs) < n_per_class or len(nonperson_imgs) < n_per_class:\n",
        "        raise ValueError(\n",
        "            f\"‚ùå Not enough images:\\n\"\n",
        "            f\"person: {len(person_imgs)} (need {n_per_class})\\n\"\n",
        "            f\"non_person: {len(nonperson_imgs)} (need {n_per_class})\"\n",
        "        )\n",
        "\n",
        "    random.shuffle(person_imgs)\n",
        "    random.shuffle(nonperson_imgs)\n",
        "\n",
        "    person_sel = person_imgs[:n_per_class]\n",
        "    nonperson_sel = nonperson_imgs[:n_per_class]\n",
        "\n",
        "    def split_list(lst, val_ratio):\n",
        "        n_val = int(len(lst) * val_ratio)\n",
        "        return lst[n_val:], lst[:n_val]  # train, val\n",
        "\n",
        "    p_train, p_val = split_list(person_sel, val_ratio)\n",
        "    n_train, n_val = split_list(nonperson_sel, val_ratio)\n",
        "\n",
        "    def copy_files(files, dst_dir):\n",
        "        for f in files:\n",
        "            dst = dst_dir / f.name\n",
        "            # avoid rare collisions\n",
        "            if dst.exists():\n",
        "                dst = dst_dir / (f\"{f.parent.name}_{f.name}\")\n",
        "            shutil.copy2(f, dst)\n",
        "\n",
        "    print(\"üß© Creating VWW 10k subset...\")\n",
        "    copy_files(p_train, subset_dir / \"train\" / \"person\")\n",
        "    copy_files(p_val,   subset_dir / \"val\"   / \"person\")\n",
        "    copy_files(n_train, subset_dir / \"train\" / \"non_person\")\n",
        "    copy_files(n_val,   subset_dir / \"val\"   / \"non_person\")\n",
        "    print(\"‚úÖ VWW subset created at:\", subset_dir)\n",
        "\n",
        "download_vww()\n",
        "extract_vww()\n",
        "vww_root = find_vww_root()\n",
        "print(\"‚úÖ Found VWW root:\", vww_root)\n",
        "make_vww_subset(vww_root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRYPLqV8eNld",
        "outputId": "55681f73-4ea1-4dd5-e2f3-6b8e1c428149"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Downloading VWW archive...\n",
            "‚úÖ Download complete: /content/vww_work/vw_coco2014_96.tar.gz\n",
            "üì¶ Extracting VWW archive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4249398104.py:38: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(extract_dir)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extraction complete: /content/vww_work/extracted\n",
            "‚úÖ Found VWW root: /content/vww_work/extracted/vw_coco2014_96\n",
            "üß© Creating VWW 10k subset...\n",
            "‚úÖ VWW subset created at: /content/vww_work/vww_10k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# VWW Dataset (same idea as before: use your local vww_10k subset)\n",
        "# ----------------------------\n",
        "base_dir = Path(\"/content/vww_work\")\n",
        "subset_dir = base_dir / \"vww_10k\"\n",
        "\n",
        "batch_size = 1\n",
        "img_size = 96\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                         (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# IMPORTANT: use your VAL split folder\n",
        "test_dataset = datasets.ImageFolder(root=str(subset_dir / \"val\"), transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "print(\"Class mapping:\", test_dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUZqfIVhdwZN",
        "outputId": "c0321e1b-f9c5-4c64-debc-244a858e4ecb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class mapping: {'non_person': 0, 'person': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# VWW Model Definition (must match training)\n",
        "# ----------------------------\n",
        "class VWWConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2) # 96 -> 48\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2) # 48 -> 24\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2) # 24 -> 12\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2) # 12 -> 6\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.training:\n",
        "            x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "A_Y5rghkedFk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Load weights (BEST VWW checkpoint)\n",
        "# ----------------------------\n",
        "model = VWWConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/stm_vww_best.pth\", map_location=torch.device(\"cpu\")))\n",
        "print(\"‚úÖ Loaded stm_vww_best.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9PyTaxQegNt",
        "outputId": "e18a1c8e-c441-48d4-84e2-6d2df393fb8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded stm_vww_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# PyTorch Accuracy on first N samples (same style)\n",
        "# ----------------------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "N = 200\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= N:\n",
        "            break\n",
        "        out = model(x)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"PyTorch accuracy on first 200:\", 100 * correct / total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKLf9TTPenrL",
        "outputId": "ce6e503c-0fea-46b5-ce7c-0626f25164cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch accuracy on first 200: 83.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FP32 Pipeline"
      ],
      "metadata": {
        "id": "Dak6Fuixe0DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export To ONNX\n",
        "def export_onnx(model, onnx_path):\n",
        "    model.eval()\n",
        "    dummy = torch.randn(1, 3, 96, 96)  # NCHW\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        export_params=True,\n",
        "        opset_version=18,\n",
        "        do_constant_folding=True,\n",
        "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"logits\": {0: \"batch_size\"}},\n",
        "        dynamo=False\n",
        "    )\n",
        "    onnx.checker.check_model(onnx_path, full_check=False)\n",
        "    print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "export_onnx(model, \"vww_convnet_fp32.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pQTEz5yetMp",
        "outputId": "5f93bac2-5da5-48b0-866a-c544681afba4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model saved to: vww_convnet_fp32.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-516851722.py:6: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect N samples (SAVE NCHW for ST to avoid any internal NHWC->NCHW conversion)\n",
        "model.eval()\n",
        "\n",
        "inputs_nchw = []\n",
        "logits = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i >= N:\n",
        "            break\n",
        "\n",
        "        out = model(x)\n",
        "\n",
        "        # Keep NCHW (1,3,96,96) -> store (3,96,96)\n",
        "        x_nchw = x.detach().cpu().numpy().astype(np.float32)         # (1,3,96,96)\n",
        "        out_np = out.detach().cpu().numpy()[0].astype(np.float32)    # (2,)\n",
        "\n",
        "        inputs_nchw.append(x_nchw[0])    # (3,96,96)\n",
        "        logits.append(out_np)            # (2,)\n",
        "        labels.append(int(y.item()))\n",
        "\n",
        "inputs_nchw = np.stack(inputs_nchw, axis=0)     # (N,3,96,96)\n",
        "logits = np.stack(logits, axis=0)               # (N,2)\n",
        "labels = np.array(labels, dtype=np.int32)       # (N,)\n",
        "\n",
        "np.savez(\"vww_val_200_io.npz\", input=inputs_nchw, logits=logits)\n",
        "np.savez(\"vww_labels_200.npz\", label=labels)\n",
        "\n",
        "print(\"Saved input shape:\", inputs_nchw.shape, \"min/max:\", inputs_nchw.min(), inputs_nchw.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXGbFre7e6rT",
        "outputId": "e7e6ca4a-084a-4248-d795-1681f2061833"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved input shape: (200, 3, 96, 96) min/max: -2.117904 2.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Accuracy (STM output NPZ)\n",
        "def compute_accuracy(\n",
        "    labels_npz_path,\n",
        "    outputs_npz_path,\n",
        "    output_key=\"c_outputs_1\",\n",
        "    num_classes=2,\n",
        "    as_percentage=False\n",
        "):\n",
        "    labels = np.load(labels_npz_path)[\"label\"].astype(np.int64)\n",
        "    out = np.load(outputs_npz_path)\n",
        "\n",
        "    logits = out[output_key].reshape(len(labels), num_classes)\n",
        "    pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    return acc * 100 if as_percentage else acc"
      ],
      "metadata": {
        "id": "fUjTzK4We-kK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example (after you run STM and get network_val_io.npz)\n",
        "acc = compute_accuracy(\"vww_labels_200.npz\", \"network_val_io.npz\", output_key=\"c_outputs_1\", num_classes=2, as_percentage=True)\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk31ioVffCPG",
        "outputId": "b61fc1e1-ff9e-4773-82ed-81dcf07ea138"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 83.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INT8 Pipeline"
      ],
      "metadata": {
        "id": "Kxg42N60ksQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibration NPZ (inputs only)\n",
        "def make_calib_npz(test_dataset, N=200, out_path=\"vww_calib_200.npz\"):\n",
        "    loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= N:\n",
        "                break\n",
        "            xs.append(x.detach().cpu().numpy()[0].astype(np.float32))  # (3,96,96)\n",
        "\n",
        "    xs = np.stack(xs, axis=0)  # (N,3,96,96)\n",
        "    np.savez(out_path, input=xs)\n",
        "    print(\"Saved calib:\", out_path, xs.shape)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "EmdCG0gGktFv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CalibReader(CalibrationDataReader):\n",
        "    def __init__(self, npz_path, input_name=\"input\"):\n",
        "        self.x = np.load(npz_path)[\"input\"].astype(np.float32)\n",
        "        self.input_name = input_name\n",
        "        self.i = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.i >= len(self.x):\n",
        "            return None\n",
        "        batch = self.x[self.i:self.i+1]  # (1,3,96,96)\n",
        "        self.i += 1\n",
        "        return {self.input_name: batch}"
      ],
      "metadata": {
        "id": "QJ-1DURAkyKZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_int8_qdq(fp32_onnx=\"vww_convnet_fp32.onnx\",\n",
        "                      calib_npz=\"vww_calib_200.npz\",\n",
        "                      int8_onnx=\"vww_convnet_int8_static_qdq.onnx\"):\n",
        "    reader = CalibReader(calib_npz, input_name=\"input\")\n",
        "\n",
        "    quantize_static(\n",
        "        model_input=fp32_onnx,\n",
        "        model_output=int8_onnx,\n",
        "        calibration_data_reader=reader,\n",
        "        quant_format=QuantFormat.QDQ,\n",
        "        activation_type=QuantType.QInt8,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        per_channel=True,\n",
        "    )\n",
        "    print(\"Saved INT8:\", int8_onnx)\n",
        "    return int8_onnx"
      ],
      "metadata": {
        "id": "t7ABN49ik0nu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calib_npz = make_calib_npz(test_dataset, N=200, out_path=\"vww_calib_200.npz\")\n",
        "quantize_int8_qdq(\"vww_convnet_fp32.onnx\", calib_npz, \"vww_convnet_int8_static_qdq.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "1D6lFX3jk3Ct",
        "outputId": "ec4d9dcd-46cc-42e7-8e6e-fea0537c7454"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved calib: vww_calib_200.npz (200, 3, 96, 96)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved INT8: vww_convnet_int8_static_qdq.onnx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vww_convnet_int8_static_qdq.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_accuracy(\"vww_labels_200.npz\", \"network_val_io.npz\", output_key=\"c_outputs_1\", num_classes=2, as_percentage=True)\n",
        "print(\"STM32 accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgcBoAUok-wt",
        "outputId": "88de172f-3dd4-47a8-c180-736803c21a02"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STM32 accuracy: 84.5\n"
          ]
        }
      ]
    }
  ]
}